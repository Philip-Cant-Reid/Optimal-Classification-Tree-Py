{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "from anytree import Node, RenderTree, PreOrderIter\n",
    "import anytree\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "print(sys.getrecursionlimit())\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Test data 2:\n",
    "\n",
    "classes = [0, 1]\n",
    "feature_names = [\"x\",\"y\",\"z\",\"class\"]\n",
    "class_attributes = [[10,12,8],[12,8,10],[8,10,12]]\n",
    "\n",
    "# Creates random data with class, class atrribute 2d array and number of datapoints per class\n",
    "def create_random_data(classes, class_attributes,n):\n",
    "    data_points = []\n",
    "    for i in range(0,n):\n",
    "        for class_type in classes:\n",
    "            new_data_point = []\n",
    "            for attribute in class_attributes[class_type]:\n",
    "                new_data_point.append(random.gauss(attribute,1.5))\n",
    "            new_data_point.append(class_type)\n",
    "            data_points.append(new_data_point)\n",
    "    return data_points\n",
    "    \n",
    "# Create test data and transform it into a data frame\n",
    "data = create_random_data(classes, class_attributes,100)\n",
    "X = to_data_frame(data, feature_names)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# creates a data frame from a list of lists\n",
    "def to_data_frame(data, feature_names):\n",
    "    return pd.DataFrame(data, columns = feature_names)\n",
    "\n",
    "#split data into decision sets\n",
    "def split_data(feature, operator, value, dataFrame):\n",
    "    try:\n",
    "        leftDataFrame = dataFrame.query('{feature} {operator} {value}'.format(feature = feature, operator = operator, value = str(value)))\n",
    "        rightDataFrame = dataFrame[~dataFrame.isin(leftDataFrame)].dropna().reset_index(drop=True)\n",
    "        leftDataFrame.reset_index(drop=True,inplace=True)\n",
    "        return leftDataFrame, rightDataFrame\n",
    "    except Exception as e:\n",
    "        print(e, feature, operator, value)\n",
    "        return None\n",
    "\n",
    "# gets all features of the dataset, removing class\n",
    "def get_features(dataFrame):\n",
    "    features = []\n",
    "    for column in dataFrame.columns:\n",
    "        if column != \"Class\":\n",
    "            features.append(column)\n",
    "    return features\n",
    "\n",
    "# Gets classes that are available in a data frame\n",
    "def get_classes(dataFrame):\n",
    "    return dataFrame[\"Class\"].unique()\n",
    "\n",
    "# untested\n",
    "def get_classes_multi(dataFrame, *dataFrames):\n",
    "    combinedDataFrame = reduce(lambda left,right: pd.merge(left,right,on='name'), [dataFrame] + [dataFrames])\n",
    "    return get_classes(combinedDataFrame)\n",
    "    \n",
    "\n",
    "\n",
    "def create_simulated_data(classes, n, d):\n",
    "    data_points = []\n",
    "    for i in range(0,n):\n",
    "        newClass = np.random.binomial(1,0.5)\n",
    "        new_data_point = []\n",
    "        if(newClass == 0):\n",
    "            # x axis\n",
    "            new_data_point.append(np.random.uniform(0,0.5,1)[0].round(3))\n",
    "            # y axis\n",
    "            new_data_point.append(np.random.uniform(0,0.5,1)[0].round(3))\n",
    "                \n",
    "        else:\n",
    "            new_data_point.append(np.random.uniform(0,1,1)[0].round(3))\n",
    "            if(new_data_point[0] <= 0.5):\n",
    "                new_data_point.append(np.random.uniform(.51,1,1)[0].round(3))\n",
    "            else:\n",
    "                new_data_point.append(np.random.uniform(0,1,1)[0].round(3))\n",
    "        new_data_point += [1 for i in range(0,d-2)]\n",
    "        new_data_point.append(newClass)\n",
    "        data_points.append(new_data_point)\n",
    "    return data_points\n",
    "\n",
    "\n",
    "n = 100\n",
    "d = 3\n",
    "simulated = create_simulated_data([0,1],n,d)\n",
    "simulatedData = to_data_frame(simulated, [\"x_{n}\".format(n = n) for n in range(0,d)]+[\"Class\"])\n",
    "test_data = pd.read_csv('Iris.csv')\n",
    "del test_data[\"Id\"]\n",
    "#test_data.plot(x=\"SepalLengthCm\",y=\"SepalWidthCm\", hue=\"Species\",kind=\"scatter\")\n",
    "#plt.show()\n",
    "\n",
    "test_data.rename(columns={'Species': 'Class'},inplace=\"True\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the error of a dataframe given a target class\n",
    "def calculate_combined_error(dataFrame, targetClass):\n",
    "    return len(dataFrame.query(\"Class != @targetClass\").index)\n",
    "\n",
    "# Calculates the error of a dataframe using the most popular class\n",
    "def popular_error(dataFrame):\n",
    "    return calculate_combined_error(dataFrame, dataFrame[\"Class\"].value_counts().first_valid_index())\n",
    "\n",
    "# Calculates the error value of how well the tree fits the data\n",
    "# Input: Tree, Dataframe\n",
    "# Recursive function\n",
    "def error_value(tree, dataFrame):\n",
    "    # misclassification error\n",
    "    error = 0\n",
    "    if not tree.is_leaf:\n",
    "        \n",
    "        # split data by decision\n",
    "        feature, operator, value = tree.name.split()\n",
    "        leftData,rightData  = split_data(feature, operator, value, dataFrame)\n",
    "        # recure through left and right nodes\n",
    "        if((not leftData.empty) and not tree.children[0].right):\n",
    "            error += error_value(tree.children[0],leftData)\n",
    "        if((not rightData.empty) and len(tree.children)>1):\n",
    "            error += error_value(tree.children[1],rightData)\n",
    "        elif((not rightData.empty) and tree.children[0].right):\n",
    "            error += error_value(tree.children[0],rightData)\n",
    "    else:\n",
    "        '''# Not actually passing the right values through\n",
    "        #print(tree.Class,tree.error,len(dataFrame.query(\"Class != '{treeClass}'\".format(treeClass = tree.Class)).index),len(data_values(tree,test_data).index))\n",
    "        if(tree.error != len(dataFrame.query(\"Class != '{treeClass}'\".format(treeClass = tree.Class)).index)):\n",
    "            print(tree, dataFrame.query(\"Class != '{treeClass}'\".format(treeClass = tree.Class)).index)\n",
    "        error = tree.error'''\n",
    "        error = len(dataFrame.query(\"Class != '{treeClass}'\".format(treeClass = tree.Class)).index)\n",
    "        \n",
    "    return error\n",
    "\n",
    "\n",
    "\n",
    "# Calculates the penalizing value for the complexity of the tree\n",
    "# Input: Tree\n",
    "# Recursive function\n",
    "def complexity(tree):\n",
    "    length = 0\n",
    "    if not tree.is_leaf:\n",
    "        # increase complexity by number of splits in the tree\n",
    "        length += 1\n",
    "        for child in tree.children:\n",
    "            length += complexity(child)\n",
    "    return length\n",
    "\n",
    "\n",
    "# calculates the loss function for the tree and the respective data\n",
    "def loss_function(tree, dataFrame, alpha = 0.5,baseLineError = 1):\n",
    "    if baseLineError <= 0:\n",
    "        baseLineError = 1\n",
    "    return (1/baseLineError) * error_value(tree, dataFrame) + alpha * complexity(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a leaf\n",
    "# Uses most populous class in available data frame\n",
    "def create_leaf(dataFrame,parent=None,right=False):\n",
    "    \n",
    "    if not dataFrame.empty:\n",
    "        \n",
    "        # Get the most populous class\n",
    "        Class = dataFrame['Class'].value_counts().first_valid_index()\n",
    "\n",
    "        # Get accuracy of class\n",
    "        accuracy = (dataFrame['Class'].value_counts().iloc[0]/len(dataFrame.index)).round(3)\n",
    "        error = calculate_combined_error(dataFrame, Class)\n",
    "        size = len(dataFrame.index)\n",
    "        \n",
    "        # Create Node using parent node\n",
    "        leaf = Node(\"class = {Class}, accuracy = {accuracy}, size = {size} error = {error}\".format(Class=Class,accuracy=accuracy,size = size, error = error),parent=parent, Class = Class, accuracy = accuracy, error = error,size = size, right = right, checked = False)\n",
    "\n",
    "        return leaf\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# recursive function for creating trees\n",
    "def create_tree(dataFrame, features, parent = None, remainingLength = 0, right = False, operators = [\"<\"], n_min = 1):\n",
    "    \n",
    "    # create node with splits\n",
    "    if(remainingLength > 0 and len(dataFrame.index) >= n_min * 2):\n",
    "        \n",
    "        \n",
    "        leftDataFrame, rightDataFrame = pd.DataFrame(), pd.DataFrame()\n",
    "        # Restrict possible dataframes by minimum data points\n",
    "        while len(leftDataFrame.index) < n_min or len(rightDataFrame.index) < n_min:\n",
    "            # split decision\n",
    "            ############################################\n",
    "            # Pick random feature and operator\n",
    "            feature, operator = random.choice(features), random.choice(operators)\n",
    "            # Choose random value in available feature\n",
    "            value = random.choice(dataFrame[feature])\n",
    "            ############################################\n",
    "            # Create decision node\n",
    "\n",
    "            \n",
    "\n",
    "            # Split dataset on decision\n",
    "            leftDataFrame, rightDataFrame = split_data(feature, operator, value, dataFrame)\n",
    "            \n",
    "        # Create decision node\n",
    "        tree = Node('{feature} {operator} {value}'.format(feature = feature,operator = operator,value = value),parent = parent, right = right, checked = False)\n",
    "        \n",
    "        # create child nodes of decision node\n",
    "        if(not leftDataFrame.empty):\n",
    "            create_tree(leftDataFrame,features,tree,remainingLength=remainingLength-1,right=False, n_min = n_min)\n",
    "        if(not rightDataFrame.empty):\n",
    "            create_tree(rightDataFrame,features,tree,remainingLength=remainingLength-1,right=True, n_min = n_min)\n",
    "    # Create a class node when at max length or no possible splits remaining\n",
    "    else:\n",
    "        # create leaf\n",
    "        tree = create_leaf(dataFrame, parent, right)\n",
    "    return tree\n",
    "\n",
    "# prints the tree in ascii\n",
    "def print_tree(tree):\n",
    "    for pre, fill, node in RenderTree(tree):\n",
    "        print(\"%s%s, %s, %s\" % (pre, node.name,\"Left\" if not node.right else \"Right\", node.checked))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trims the dataset to appropriate data for the node\n",
    "# Recurses from bottom to top\n",
    "def data_values(node, dataFrame,right = None):\n",
    "    \n",
    "    # trim data starting from parent value\n",
    "    if node.parent:\n",
    "        dataFrame = data_values(node.parent,dataFrame,node.right)\n",
    "        \n",
    "    # if data is being split at node and the node has a split\n",
    "    # Split data according to next node direction\n",
    "    if right != None and node.children:\n",
    "        \n",
    "        feature, operator, value = node.name.split()\n",
    "        return split_data(feature, operator, value, dataFrame)[int(right)]\n",
    "    # If leaf or not splitting data at node\n",
    "    # Return data at that node\n",
    "    else:\n",
    "        return dataFrame\n",
    "\n",
    "# Verifies if all leaves in a tree have the minimum amount of data points\n",
    "def verify_minimum_leaves(tree, n_min = 1):\n",
    "    truth = True\n",
    "    if tree.is_leaf:\n",
    "        if tree.size < n_min:\n",
    "            truth = False\n",
    "    else:\n",
    "        for child in tree.children:\n",
    "            truth = truth == verify_minimum_leaves(child, n_min)\n",
    "    \n",
    "    return truth\n",
    "\n",
    "# Exhaustively finds the local optimal data split of a node while keeping it's children\n",
    "def get_leaves(tree):\n",
    "    leaves = []\n",
    "    if not tree.is_leaf:\n",
    "        for children in tree.children:\n",
    "            leaves += get_leaves(children)\n",
    "    else:\n",
    "        leaves.append(tree)\n",
    "    return leaves\n",
    "\n",
    "def leaves_to_dict(tree):\n",
    "    leaf_dict = {}\n",
    "    leaves = get_leaves(tree)\n",
    "    for leaf in leaves:\n",
    "        leaf_dict[hash(leaf)] = 0\n",
    "    return leaf_dict\n",
    "\n",
    "def put_leaf_dict_data(tree, dataFrame, leafDict):\n",
    "    # Update children of tree\n",
    "    if not tree.is_leaf:\n",
    "        \n",
    "        # Get new data split for child nodes\n",
    "        feature, operator, value = tree.name.split()\n",
    "        leftData,rightData  = split_data(feature, operator, value, dataFrame)\n",
    "        # Recure through all children\n",
    "        if((not leftData.empty) and not tree.children[0].right):\n",
    "            put_leaf_dict_data(tree.children[0],leftData,leafDict)\n",
    "        if((not rightData.empty) and len(tree.children)>1):\n",
    "            put_leaf_dict_data(tree.children[1],rightData,leafDict)\n",
    "        elif((not rightData.empty) and tree.children[0].right):\n",
    "            put_leaf_dict_data(tree.children[0],rightData,leafDict)\n",
    "    else:\n",
    "        leafDict[hash(tree)] = dataFrame['Class'].value_counts()\n",
    "\n",
    "def minus_leaf_dict_data(tree, dataFrame, leafDict):\n",
    "    # Update children of tree\n",
    "    if not tree.is_leaf:\n",
    "        \n",
    "        # Get new data split for child nodes\n",
    "        feature, operator, value = tree.name.split()\n",
    "        leftData,rightData  = split_data(feature, operator, value, dataFrame)\n",
    "        # Recure through all children\n",
    "        if((not leftData.empty) and not tree.children[0].right):\n",
    "            minus_leaf_dict_data(tree.children[0],leftData,leafDict)\n",
    "        if((not rightData.empty) and len(tree.children)>1):\n",
    "            minus_leaf_dict_data(tree.children[1],rightData,leafDict)\n",
    "        elif((not rightData.empty) and tree.children[0].right):\n",
    "            minus_leaf_dict_data(tree.children[0],rightData,leafDict)\n",
    "    else:\n",
    "        leafDict[hash(tree)] = leafDict[hash(tree)].subtract(dataFrame['Class'].value_counts(),fill_value = 0).sort_values(ascending = False)\n",
    "\n",
    "def plus_leaf_dict_data(tree, dataFrame, leafDict):\n",
    "    # Update children of tree\n",
    "    if not tree.is_leaf:\n",
    "        \n",
    "        # Get new data split for child nodes\n",
    "        feature, operator, value = tree.name.split()\n",
    "        leftData,rightData  = split_data(feature, operator, value, dataFrame)\n",
    "        # Recure through all children\n",
    "        if((not leftData.empty) and not tree.children[0].right):\n",
    "            plus_leaf_dict_data(tree.children[0],leftData,leafDict)\n",
    "        if((not rightData.empty) and len(tree.children)>1):\n",
    "            plus_leaf_dict_data(tree.children[1],rightData,leafDict)\n",
    "        elif((not rightData.empty) and tree.children[0].right):\n",
    "            plus_leaf_dict_data(tree.children[0],rightData,leafDict)\n",
    "    else:\n",
    "        leafDict[hash(tree)] = dataFrame['Class'].value_counts().add(leafDict[hash(tree)],fill_value = 0).sort_values(ascending = False)\n",
    "\n",
    "def series_error(series):\n",
    "    return series.sum() -  series.iloc[0] \n",
    "\n",
    "def check_dict_error(item):\n",
    "    if type(item) == pd.Series:\n",
    "        return series_error(item)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_dict_error(leafDict):\n",
    "    error = 0\n",
    "    for key in leafDict.keys():\n",
    "        error += check_dict_error(leafDict[key])\n",
    "    return error\n",
    "\n",
    "def get_each_dict_error(leafDict):\n",
    "    for key in leafDict.keys():\n",
    "        print(leafDict[key])\n",
    "        print(check_dict_error(leafDict[key]))\n",
    "\n",
    "def optimal_node_data_split_dict(node, dataFrame, operators=[\"<\"], alpha = 0.5, baseLineError = 1, n_min = 1): \n",
    "    print(\"Size of data set\", len(dataFrame.index),\"Baseline error for optimal node split: \", calculate_baseline_error(dataFrame))\n",
    "    #node, dataFrame, operators=[\"<\"], n_min = 1, alpha = 0.5, baseLineError = 1\n",
    "    childNodes = [copy.deepcopy(childNode) for childNode in node.children]\n",
    "    bestError = [np.inf,\"\",\"\",\"\"]\n",
    "    tree_dict = leaves_to_dict(node)\n",
    "    if(len(childNodes)==2):\n",
    "        leftNode = childNodes[0]\n",
    "        rightNode = childNodes[1]\n",
    "        for feature in get_features(dataFrame):\n",
    "            left_cumulative_error = []\n",
    "            right_cumulative_error = []\n",
    "            values = dataFrame[feature].drop_duplicates().sort_values().reset_index(drop=True)\n",
    "            n = len(values.index)\n",
    "            \n",
    "            # For every feature, reset left and right dictionary\n",
    "            left_leaf_dict = leaves_to_dict(leftNode)\n",
    "            right_leaf_dict = leaves_to_dict(rightNode)\n",
    "            put_leaf_dict_data(rightNode, dataFrame, right_leaf_dict)\n",
    "            for i, point in enumerate(values[:-1]):\n",
    "                samePoints = dataFrame.query('{feature} == {value}'.format(feature = feature,value = point))\n",
    "                minus_leaf_dict_data(rightNode, samePoints, right_leaf_dict)\n",
    "                plus_leaf_dict_data(leftNode, samePoints, left_leaf_dict)\n",
    "                \n",
    "                new_error = get_dict_error(left_leaf_dict) + get_dict_error(right_leaf_dict)\n",
    "                if(new_error < bestError[0]):\n",
    "                    #print(\"new Best Error: \", new_error)\n",
    "                    try:\n",
    "                        bestError = [new_error,feature,\"<\",(1/2 * (values.iloc[i] + values.iloc[i+1])).round(2)]\n",
    "                        print(bestError)\n",
    "                    except:\n",
    "                        print(\"i: \",i,\"/\",n)\n",
    "        bestErrorNode = Node('{feature} {operator} {value}'.format(feature = bestError[1],operator = bestError[2],value = bestError[3]), children = childNodes)#, checked = True)\n",
    "        if(childNodes):\n",
    "            # Update children of replacement node at new decision point\n",
    "            update_tree(bestErrorNode,dataFrame)\n",
    "            #bestErrorNode.checked = True\n",
    "        else:\n",
    "            # Create children at new decision point for nodes which were previously leaves\n",
    "            leftDataFrame,rightDataFrame = split_data(bestError[1],\"<\",bestError[3],dataFrame)\n",
    "            create_leaf(leftDataFrame,parent=bestErrorNode,right=False)\n",
    "            create_leaf(rightDataFrame,parent=bestErrorNode,right=True)\n",
    "        return bestErrorNode\n",
    "    else:\n",
    "        return delete_split(node, dataFrame, alpha, baseLineError)\n",
    "    \n",
    "#######\n",
    "\n",
    "def place_left_node(node):\n",
    "    if (not node.right and node.parent):\n",
    "        if(len(node.parent.children)>1):\n",
    "            node.parent.children = [node.parent.children[1],node.parent.children[0]]\n",
    "    \n",
    "# Create new split at given node\n",
    "def optimal_split(node, dataFrame, alpha = 0.5, baseLineError = 1, n_min = 1):\n",
    "    \n",
    "    # Extract set of features\n",
    "    features = get_features(dataFrame)\n",
    "    \n",
    "    # Create new optimal split if it does not violate minimum number of data points\n",
    "    if(len(dataFrame.index)) >= n_min * 2:\n",
    "        \n",
    "        # Create parallel split\n",
    "        tree = optimal_node_data_split_dict(node, dataFrame, alpha = alpha, baseLineError = baseLineError, n_min = n_min)\n",
    "        # Add new split node to tree\n",
    "        parent = node.parent\n",
    "        right = node.right\n",
    "        tree.right = right\n",
    "        tree.parent = parent\n",
    "        \n",
    "        # Remove old split node from tree\n",
    "        node.parent = None\n",
    "        # Place left nodes back on left\n",
    "        place_left_node(tree)\n",
    "        \n",
    "        # change node to decision\n",
    "        return tree\n",
    "    else:\n",
    "        return node\n",
    "\n",
    "# Updates tree with new data values\n",
    "def update_tree(tree, dataFrame, n_min = 1):\n",
    "    # Reset checked flag\n",
    "    tree.checked = False\n",
    "    \n",
    "    # Update children of tree\n",
    "    if not tree.is_leaf:\n",
    "        \n",
    "        # Get new data split for child nodes\n",
    "        feature, operator, value = tree.name.split()\n",
    "        leftData,rightData  = split_data(feature, operator, value, dataFrame)\n",
    "        \n",
    "        # Recure through all children\n",
    "        if((not leftData.empty) and not tree.children[0].right):\n",
    "            update_tree(tree.children[0],leftData)\n",
    "        if((not rightData.empty) and len(tree.children)>1):\n",
    "            update_tree(tree.children[1],rightData)\n",
    "        elif((not rightData.empty) and tree.children[0].right):\n",
    "            update_tree(tree.children[0],rightData)\n",
    "    else:\n",
    "        # debugging\n",
    "        if(len(dataFrame.index) == 0):\n",
    "            print(\" No items at tree: \", tree)\n",
    "        \n",
    "        \n",
    "        # Update leaf for new data points\n",
    "        Class = dataFrame['Class'].value_counts().first_valid_index()\n",
    "        tree.error = calculate_combined_error(dataFrame, Class)\n",
    "        tree.size = len(dataFrame.index)\n",
    "        tree.accuracy =  (dataFrame['Class'].value_counts().iloc[0]/len(dataFrame.index)).round(3)\n",
    "        tree.name = \"class = {Class}, accuracy = {accuracy}, size = {size} error = {error}\".format(Class=Class,accuracy=tree.accuracy,size = tree.size, error = tree.error)\n",
    "        tree.Class =  Class\n",
    "\n",
    "    \n",
    "# Delete the split at the given node\n",
    "def delete_split(node, dataFrame, alpha = 0.5, baseLineError = 1):\n",
    "    # Set default node to original node\n",
    "    newNode = node\n",
    "    \n",
    "    # Check if node has children\n",
    "    if node.children:\n",
    "        \n",
    "        # If multiple children\n",
    "        if len(node.children) > 1:\n",
    "            \n",
    "            # Try replacing with left child\n",
    "            leftNode = copy.deepcopy(node.children[0])\n",
    "            \n",
    "            # Try replacing with right child\n",
    "            rightNode = copy.deepcopy(node.children[1])\n",
    "            \n",
    "            \n",
    "            # Get loss of original node\n",
    "            currentLoss = loss_function(node, dataFrame, alpha, baseLineError)\n",
    "            \n",
    "            # Update children of left and right node with new data\n",
    "            try:\n",
    "                update_tree(leftNode,dataFrame)\n",
    "            except:\n",
    "                print(20*\"Big Error \\n\")\n",
    "                print_tree(get_root(leftNode))\n",
    "                print(\"leftNode:\", leftNode)\n",
    "                \n",
    "                print(\"node\", node)\n",
    "                print(dataFrame)\n",
    "                \n",
    "            try:\n",
    "                update_tree(rightNode,dataFrame)\n",
    "            except:\n",
    "                print(20*\"Big Error \\n\")\n",
    "                print_tree(get_root(rightNode))\n",
    "                print(\"rightNode:\", rightNode)\n",
    "                \n",
    "                print(\"node\", node)\n",
    "                print(dataFrame)\n",
    "            \n",
    "            # Get loss of new updated left and right trees\n",
    "            rightLoss = loss_function(rightNode, dataFrame, alpha, baseLineError)\n",
    "            leftLoss = loss_function(leftNode, dataFrame, alpha, baseLineError)\n",
    "            \n",
    "            # Replace old node with left or right node if they have lower loss\n",
    "            if leftLoss < rightLoss:\n",
    "                if leftLoss < currentLoss:\n",
    "                    newNode = copy.deepcopy(leftNode)\n",
    "            else:\n",
    "                if rightLoss < currentLoss:\n",
    "                    newNode = copy.deepcopy(rightNode)\n",
    "            \n",
    "            \n",
    "            \n",
    "            if newNode != node:\n",
    "                \n",
    "                # Add new node to tree\n",
    "                newNode.parent = node.parent\n",
    "                \n",
    "                # get the position of the node relative to the parent\n",
    "                newNode.right = node.right\n",
    "                \n",
    "                # Remove original node from tree\n",
    "                node.parent = None\n",
    "                \n",
    "                # Reset left positioned nodes\n",
    "                place_left_node(newNode)\n",
    "                \n",
    "        # Single child\n",
    "        else:\n",
    "            newNode = node.children[0]\n",
    "            \n",
    "    return newNode\n",
    "\n",
    "# Create a new split at the node\n",
    "def update_split(node, dataFrame, alpha = 0.5, baseLineError = 1, n_min = 1):\n",
    "    # replace previous split with new optimal split\n",
    "    return optimal_split(node,dataFrame, alpha, baseLineError, n_min)\n",
    "\n",
    "# Creates a new split at a leaf\n",
    "def create_split(node, dataFrame, alpha = 0.5, baseLineError = 1, n_min = 1):\n",
    "    \n",
    "    newNode = node\n",
    "    \n",
    "    if node.is_leaf:\n",
    "        \n",
    "        # Only creates leaf if accuracy cannot be improved or improved node would violate minimum data count at leaves\n",
    "        if node.accuracy < 1 and len(dataFrame.index) >= n_min * 2:\n",
    "            \n",
    "            newNode = optimal_split(node, dataFrame, alpha, baseLineError, n_min)\n",
    "    \n",
    "    # Incase non-leaves are run through create split\n",
    "    else:\n",
    "        newNode = optimal_split(node, dataFrame, alpha, baseLineError, n_min)\n",
    "        \n",
    "    return newNode\n",
    "            \n",
    "# Returns random unchecked node from tree\n",
    "def get_random_node(tree):\n",
    "    availableNodes = [node for node in PreOrderIter(tree) if not node.checked]\n",
    "    #availableNodes = [tree.root]\n",
    "    if availableNodes:\n",
    "        return random.choice(availableNodes)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Gets root of node\n",
    "# If no root, returns node\n",
    "def get_root(node):\n",
    "    if(node.root):\n",
    "        return node.root\n",
    "    else:\n",
    "        return node\n",
    "\n",
    "# Calculates baseline error of a dataset\n",
    "def calculate_baseline_error(dataFrame):\n",
    "    return len(dataFrame.index) - dataFrame[\"Class\"].value_counts().iloc[0]\n",
    "\n",
    "# Unchecks all parents of a node recursively\n",
    "def uncheck_parents(node):\n",
    "    if node.parent:\n",
    "        node.parent.checked = False\n",
    "        uncheck_parents(node.parent)\n",
    "\n",
    "# Replaces a tree with a deep copy of a tree from a given node and unchecks parents of given node\n",
    "def replace_tree(newNode):\n",
    "    uncheck_parents(newNode)\n",
    "    return copy.deepcopy(get_root(newNode)), True\n",
    "\n",
    "# Main loop for creating Optimal Classification Trees\n",
    "def random_node_modification(tree, dataFrame, n_min = 1, D_max = 5, alpha = 0.5):\n",
    "    \n",
    "    # Calculate baseline error of data\n",
    "    baseLineError = calculate_baseline_error(dataFrame)\n",
    "    \n",
    "    # Loops through while unchecked nodes are in the tree\n",
    "    while get_random_node(tree):\n",
    "        \n",
    "        # Set improvement check\n",
    "        improvement = False\n",
    "        \n",
    "        # Pick random unchecked node for modification\n",
    "        node = get_random_node(tree)\n",
    "        \n",
    "        # Get data frame at specific node\n",
    "        dataFrameNode = data_values(node,dataFrame)\n",
    "        \n",
    "        # Get loss of picked node\n",
    "        loss = loss_function(node, dataFrameNode, alpha, baseLineError)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Runs update (parallel) split and delete split on decision nodes\n",
    "        if not node.is_leaf:\n",
    "            \n",
    "            # Creates deep copy of node to improve\n",
    "            testNode = copy.deepcopy(node)\n",
    "            \n",
    "            # Tries replacing node with one of it's children\n",
    "            newNode = delete_split(testNode, dataFrameNode, alpha, baseLineError)\n",
    "            \n",
    "            # Calculates loss for new updated tree\n",
    "            newLoss = loss_function(newNode,dataFrameNode, alpha, baseLineError)\n",
    "            \n",
    "            # Replaces original node if new node is better\n",
    "            if newLoss < loss:\n",
    "                \n",
    "                tree, improvement =  replace_tree(newNode)\n",
    "                print(\"Deleted split: \\n\", newNode)\n",
    "                print_tree(tree)\n",
    "                # Update loss in case optimal split overrides\n",
    "                loss = loss_function(newNode, dataFrameNode, alpha, baseLineError)\n",
    "            \n",
    "            \n",
    "            # Creates deep copy of node to improve\n",
    "            testNode = copy.deepcopy(node)\n",
    "            \n",
    "            # Tries replacing node with a parallel split node\n",
    "            newNode = update_split(testNode, dataFrameNode, alpha, baseLineError, n_min)\n",
    "            \n",
    "            # Calculates loss for new updated tree\n",
    "            newLoss = loss_function(newNode,dataFrameNode, alpha, baseLineError)\n",
    "            \n",
    "            # Replaces original node if new node is better\n",
    "            if newLoss < loss:\n",
    "                print(\"Updated split: \\n\", newNode)\n",
    "                tree, improvement =  replace_tree(newNode)\n",
    "                print_tree(tree)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # Only creates new split if leaf is not at max depth\n",
    "            if node.depth < D_max:\n",
    "                \n",
    "                # Creates deep copy of node to improve\n",
    "                testNode = copy.deepcopy(node)\n",
    "                \n",
    "                # Tries creating new node to replace leaf\n",
    "                newNode = create_split(testNode, dataFrameNode, alpha, baseLineError, n_min)\n",
    "                \n",
    "                # Calculates loss for new updated tree\n",
    "                newLoss = loss_function(newNode, dataFrameNode, alpha, baseLineError)\n",
    "                \n",
    "                # Replaces original node if new node is better\n",
    "                if newLoss < loss:\n",
    "                    print(\"Created split: \\n\", newNode)\n",
    "                    tree, improvement =  replace_tree(newNode)\n",
    "                    print_tree(tree)\n",
    "        \n",
    "        # Check the node if not improved\n",
    "        if not improvement:\n",
    "            node.checked = True\n",
    "        \n",
    "        # Reset Improvement check\n",
    "        improvement = False\n",
    "        \n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds best local optimum tree with given hyperparameters and tree count\n",
    "def best_local_optimum_tree(dataFrame, n = 1, n_min = 1, D_max = 5, alpha = 0.5):\n",
    "    \n",
    "    # Initialse baseline\n",
    "    baseLineError = calculate_baseline_error(dataFrame)\n",
    "    \n",
    "    # Intiliase error for baseline leaf\n",
    "    optimalTree = create_leaf(dataFrame)\n",
    "    bestLoss = loss_function(optimalTree, dataFrame, alpha, baseLineError)\n",
    "    print(bestLoss)\n",
    "    # Loop through number of trees\n",
    "    for i in range(0,n):\n",
    "        print(\"Starting tree: \", i)\n",
    "        # Create random tree\n",
    "        startingTree = create_tree(dataFrame, get_features(dataFrame), remainingLength = D_max - 1, n_min = n_min)\n",
    "        print_tree(startingTree)\n",
    "        # Run optimal tree function to find local optimum tree\n",
    "        localOptimalTree = random_node_modification(startingTree,test_data,alpha = alpha, D_max = D_max, n_min = n_min)\n",
    "        \n",
    "        # Get loss of local optimum tree\n",
    "        localLoss = loss_function(localOptimalTree, dataFrame, alpha, baseLineError)\n",
    "        print_tree(localOptimalTree)\n",
    "        print(\"Error: \",localLoss)\n",
    "        # Replace best tree with new local optimum tree if better\n",
    "        if(localLoss < bestLoss):\n",
    "            print_tree(localOptimalTree)\n",
    "            optimalTree = copy.deepcopy(localOptimalTree)\n",
    "            print_tree(optimalTree)\n",
    "            # Update best loss\n",
    "            bestLoss = localLoss\n",
    "    \n",
    "    return optimalTree\n",
    "#optimalTree = best_local_optimum_tree(test_data, 100, 1, 5, 0.01)\n",
    "#print_tree(optimalTree)\n",
    "#startingTree = create_tree(test_data, get_features(test_data), remainingLength = 5 - 1, n_min = 1)\n",
    "#print_tree(startingTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_node_data_split(node, dataFrame, operators=[\"<\"], alpha = 0.5, baseLineError = 1, n_min = 1): \n",
    "    print_tree(node)\n",
    "    #node, dataFrame, operators=[\"<\"], n_min = 1, alpha = 0.5, baseLineError = 1\n",
    "    childNodes = [copy.deepcopy(childNode) for childNode in node.children]\n",
    "    bestError = [np.inf,\"\",\"\",\"\"]\n",
    "    print(dataFrame)\n",
    "    if(len(childNodes)==2):\n",
    "        leftNode = childNodes[0]\n",
    "        rightNode = childNodes[1]\n",
    "        \n",
    "        for feature in get_features(dataFrame):\n",
    "            left_cumulative_error = []\n",
    "            right_cumulative_error = []\n",
    "            values = dataFrame[feature].drop_duplicates().sort_values().reset_index(drop=True)\n",
    "            n = len(values.index)\n",
    "            for i,point in enumerate(values):\n",
    "                \n",
    "                samePoints = dataFrame.query('{feature} == {value}'.format(feature = feature,value = point))\n",
    "                print(samePoints)\n",
    "                print(point,error_value(leftNode,samePoints),error_value(rightNode,samePoints))\n",
    "                \n",
    "                #Replace \"error_value\" with function that can manipulate \n",
    "                if(i==0):\n",
    "                    left_cumulative_error.append(error_value(leftNode,samePoints))\n",
    "                    right_cumulative_error.append(error_value(rightNode,samePoints))\n",
    "                else:\n",
    "                    left_cumulative_error.append(error_value(leftNode,samePoints) + left_cumulative_error[-1])\n",
    "                    right_cumulative_error.insert(0,error_value(rightNode,samePoints) + right_cumulative_error[0])\n",
    "            print(feature)\n",
    "            print(left_cumulative_error)\n",
    "            print(right_cumulative_error)\n",
    "            if(len(left_cumulative_error) == len(right_cumulative_error)):\n",
    "                for i in range(0,len(left_cumulative_error)):\n",
    "                    new_error = left_cumulative_error[i] + right_cumulative_error[i]\n",
    "                    if(new_error < bestError[0]):\n",
    "                            \n",
    "                        bestError = [new_error,feature,\"<\",(1/2 * (values.iloc[i] + values.iloc[i+1]))]\n",
    "                        print(bestError)\n",
    "        bestErrorNode = Node('{feature} {operator} {value}'.format(feature = bestError[1],operator = bestError[2],value = bestError[3], children = childNodes, checked = True))\n",
    "        if(childNodes):\n",
    "            # Update children of replacement node at new decision point\n",
    "            update_tree(bestErrorNode,dataFrame)\n",
    "            bestErrorNode.checked = True\n",
    "        else:\n",
    "            # Create children at new decision point for nodes which were previously leaves\n",
    "            leftDataFrame,rightDataFrame = split_data(bestError[1],\"<\",bestError[3],dataFrame)\n",
    "            create_leaf(leftDataFrame,parent=bestErrorNode,right=False)\n",
    "            create_leaf(rightDataFrame,parent=bestErrorNode,right=True)\n",
    "        return bestErrorNode\n",
    "    else:\n",
    "        return delete_split(node, dataFrame, alpha, baseLineError)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
