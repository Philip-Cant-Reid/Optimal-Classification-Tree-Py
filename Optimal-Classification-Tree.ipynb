{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anytree import Node, RenderTree, PreOrderIter\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# creates a data frame from a list of lists\n",
    "def to_data_frame(data, feature_names):\n",
    "    return pd.DataFrame(data, columns = feature_names)\n",
    "\n",
    "#split data into decision sets\n",
    "def split_data(dataFrame, feature, operator, value):\n",
    "    try:\n",
    "        leftDataFrame = dataFrame.query('{feature} {operator} {value}'.format(feature = feature, operator = operator, value = str(value))).reset_index(drop=True)\n",
    "        rightDataFrame = dataFrame.query('~({feature} {operator} {value})'.format(feature = feature, operator = operator, value = str(value))).reset_index(drop=True)\n",
    "        return leftDataFrame, rightDataFrame\n",
    "    except Exception as e:\n",
    "        print(e,get_features(dataFrame), feature, operator, value)\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "# gets all features of the dataset, removing class\n",
    "def get_features(dataFrame):\n",
    "    features = []\n",
    "    for column in dataFrame.columns:\n",
    "        if column != \"Class\":\n",
    "            features.append(column)\n",
    "    return features\n",
    "\n",
    "# Gets classes that are available in a data frame\n",
    "def get_classes(dataFrame):\n",
    "    return dataFrame[\"Class\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Error and Loss calculations\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Calculates the error of a dataframe given a target class\n",
    "def calculate_combined_error(dataFrame, targetClass):\n",
    "    return len(dataFrame.query(\"Class != @targetClass\").index)\n",
    "\n",
    "# Calculates the error of a dataframe using the most popular class\n",
    "def popular_error(dataFrame):\n",
    "    return calculate_combined_error(dataFrame, dataFrame[\"Class\"].value_counts().first_valid_index())\n",
    "\n",
    "# Calculates the error value of how well the tree fits the data\n",
    "# Input: Tree, Dataframe\n",
    "# Recursive function\n",
    "def error_value(tree, dataFrame):\n",
    "    # misclassification error\n",
    "    error = 0\n",
    "    if not tree.is_leaf:\n",
    "        \n",
    "        # split data by decision\n",
    "        feature, operator, value = tree.name.split()\n",
    "        leftData,rightData  = split_data(dataFrame, feature, operator, value)\n",
    "        # recure through left and right nodes\n",
    "        if((not leftData.empty) and not tree.children[0].right):\n",
    "            error += error_value(tree.children[0],leftData)\n",
    "        if((not rightData.empty) and len(tree.children)>1):\n",
    "            error += error_value(tree.children[1],rightData)\n",
    "        elif((not rightData.empty) and tree.children[0].right):\n",
    "            error += error_value(tree.children[0],rightData)\n",
    "    else:\n",
    "        error = len(dataFrame.query(\"Class != '{treeClass}'\".format(treeClass = tree.Class)).index)\n",
    "        \n",
    "    return error\n",
    "\n",
    "\n",
    "\n",
    "# Calculates the penalizing value for the complexity of the tree\n",
    "# Input: Tree\n",
    "# Recursive function\n",
    "def complexity(tree):\n",
    "    length = 0\n",
    "    if not tree.is_leaf:\n",
    "        # increase complexity by number of splits in the tree\n",
    "        length += 1\n",
    "        for child in tree.children:\n",
    "            length += complexity(child)\n",
    "    return length\n",
    "\n",
    "\n",
    "# calculates the loss function for the tree and the respective data\n",
    "def loss_function(tree, dataFrame, alpha = 0.5,baseLineError = 1):\n",
    "    if baseLineError <= 0:\n",
    "        baseLineInverse = 0\n",
    "    else:\n",
    "        baseLineInverse = (1/baseLineError)\n",
    "    return (1/baseLineError) * error_value(tree, dataFrame) + alpha * complexity(tree)\n",
    "\n",
    "# calculates the loss function for the tree and the respective data\n",
    "def dict_loss_function(tree, error_dict, alpha = 0.5,baseLineError = 1):\n",
    "    if baseLineError <= 0:\n",
    "        baseLineInverse = 0\n",
    "    else:\n",
    "        baseLineInverse = (1/baseLineError)\n",
    "    return baseLineInverse * get_dict_error(error_dict) + alpha * complexity(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_features(dataFrame, features, printErrors = False):\n",
    "    if(printErrors):\n",
    "        print(*((\"Error\", feature, \" not in list\") for feature in features if feature not in get_features(dataFrame)), sep='\\n')\n",
    "    if features:\n",
    "        return [feature for feature in features if feature in get_features(dataFrame)]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "#def check_splits(dataframe, n_min):\n",
    "    #if len(dataFrame.index) > n_min * 2\n",
    "    # and either \n",
    "    #     2 n_min unique values\n",
    "    #     n_min <= 2 and 2 unique sets of duplicates\n",
    "    #     n_min > 2 and bin packing \n",
    "    #elif unique values are \n",
    "    #\n",
    "\n",
    "# Create a leaf\n",
    "# Uses most populous class in available data frame\n",
    "def create_leaf(dataFrame,parent=None,right=False):\n",
    "    \n",
    "    if not dataFrame.empty:\n",
    "        \n",
    "        # Get the most populous class\n",
    "        Class = dataFrame['Class'].value_counts().first_valid_index()\n",
    "\n",
    "        # Get accuracy of class\n",
    "        accuracy = (dataFrame['Class'].value_counts().iloc[0]/len(dataFrame.index)).round(3)\n",
    "        error = calculate_combined_error(dataFrame, Class)\n",
    "        size = len(dataFrame.index)\n",
    "        \n",
    "        # Create Node using parent node\n",
    "        leaf = Node(\"class = {Class}, accuracy = {accuracy}, size = {size} error = {error}\".format(Class=Class,accuracy=accuracy,size = size, error = error),parent=parent, Class = Class, accuracy = accuracy, error = error,size = size, right = right, checked = False)\n",
    "\n",
    "        return leaf\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# recursive function for creating random trees\n",
    "def random_tree(dataFrame, features = None, parent = None, remainingDepth = 0, right = False, operators = [\"<\"], n_min = 1):\n",
    "    if(n_min < 1):\n",
    "        n_min = 1\n",
    "    # create node with splits\n",
    "    if(remainingDepth > 0 and len(dataFrame.index) >= n_min * 2):\n",
    "        features = check_features(dataFrame,features)\n",
    "        if not features or len(features) == 0:\n",
    "            features = get_features(dataFrame)\n",
    "        \n",
    "        # Add check to ensure that a split is even possible, points may share same values\n",
    "        leftDataFrame, rightDataFrame = pd.DataFrame(), pd.DataFrame()\n",
    "        # Restrict possible dataframes by minimum data points\n",
    "        i = 0\n",
    "        loopLimit = 5\n",
    "        while (len(leftDataFrame.index) < n_min or len(rightDataFrame.index) < n_min) and i < loopLimit:\n",
    "            # split decision\n",
    "            ############################################\n",
    "            # Pick random feature and operator\n",
    "            feature, operator = random.choice(features), random.choice(operators)\n",
    "            # Choose random value in available feature\n",
    "            value = random.choice(dataFrame[feature])\n",
    "            ############################################\n",
    "            \n",
    "\n",
    "            # Split dataset on decision\n",
    "            leftDataFrame, rightDataFrame = split_data(dataFrame, feature, operator, value)\n",
    "            if (len(leftDataFrame.index) < n_min or len(rightDataFrame.index) < n_min):\n",
    "                i += 1\n",
    "            \n",
    "        if i < loopLimit:\n",
    "            # Create decision node\n",
    "            tree = Node('{feature} {operator} {value}'.format(feature = feature,operator = operator,value = value),parent = parent, right = right, checked = False)\n",
    "\n",
    "            # create child nodes of decision node\n",
    "            random_tree(leftDataFrame,features,tree,remainingDepth=remainingDepth-1,right=False, operators=operators, n_min = n_min)\n",
    "            random_tree(rightDataFrame,features,tree,remainingDepth=remainingDepth-1,right=True, operators=operators, n_min = n_min)\n",
    "            \n",
    "        else:\n",
    "            tree = create_leaf(dataFrame, parent, right)\n",
    "        # Create a class node when at max length or no possible splits remaining\n",
    "    else:\n",
    "        # create leaf\n",
    "        tree = create_leaf(dataFrame, parent, right)\n",
    "    return tree\n",
    "\n",
    "# prints the tree in ascii\n",
    "def print_tree(tree):\n",
    "    for pre, fill, node in RenderTree(tree):\n",
    "        print(\"%s%s, %s, %s\" % (pre, node.name,\"Left\" if not node.right else \"Right\", node.checked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "\n",
    "# Trims the dataset to appropriate data for the node\n",
    "# Recurses from bottom to top\n",
    "def data_values(node, dataFrame,right = None):\n",
    "    \n",
    "    # trim data starting from parent value\n",
    "    if node.parent:\n",
    "        dataFrame = data_values(node.parent,dataFrame,node.right)\n",
    "        \n",
    "    # if data is being split at node and the node has a split\n",
    "    # Split data according to next node direction\n",
    "    if right != None and node.children:\n",
    "        \n",
    "        feature, operator, value = node.name.split()\n",
    "        return split_data(dataFrame, feature, operator, value)[int(right)]\n",
    "    # If leaf or not splitting data at node\n",
    "    # Return data at that node\n",
    "    else:\n",
    "        return dataFrame\n",
    "\n",
    "# Verifies if all leaves in a tree have the minimum amount of data points\n",
    "def verify_minimum_leaves(tree, n_min = 1):\n",
    "    truth = True\n",
    "    if tree.is_leaf:\n",
    "        if tree.size < n_min:\n",
    "            truth = False\n",
    "    else:\n",
    "        for child in tree.children:\n",
    "            truth = truth == verify_minimum_leaves(child, n_min)\n",
    "    \n",
    "    return truth\n",
    "\n",
    "############################################################\n",
    "\n",
    "# Gets list of leaves of tree\n",
    "def get_leaves(tree):\n",
    "    leaves = []\n",
    "    if not tree.is_leaf:\n",
    "        for children in tree.children:\n",
    "            leaves += get_leaves(children)\n",
    "    else:\n",
    "        leaves.append(tree)\n",
    "    return leaves\n",
    "\n",
    "# Creates dictionary of hashed leaves with values of 0\n",
    "# Used for abstraction of leaves\n",
    "def leaves_to_dict(tree):\n",
    "    leaf_dict = {}\n",
    "    leaves = get_leaves(tree)\n",
    "    for leaf in leaves:\n",
    "        leaf_dict[hash(leaf)] = 0\n",
    "    return leaf_dict\n",
    "\n",
    "#  Updates hashed leaf dictionary with data\n",
    "def put_leaf_dict_data(tree, dataFrame, leafDict):\n",
    "    # Update children of tree\n",
    "    if not tree.is_leaf:\n",
    "        \n",
    "        # Get new data split for child nodes\n",
    "        feature, operator, value = tree.name.split()\n",
    "        leftData,rightData  = split_data(dataFrame, feature, operator, value)\n",
    "        # Recure through all children\n",
    "        if((not leftData.empty) and not tree.children[0].right):\n",
    "            put_leaf_dict_data(tree.children[0],leftData,leafDict)\n",
    "        if((not rightData.empty) and len(tree.children)>1):\n",
    "            put_leaf_dict_data(tree.children[1],rightData,leafDict)\n",
    "        elif((not rightData.empty) and tree.children[0].right):\n",
    "            put_leaf_dict_data(tree.children[0],rightData,leafDict)\n",
    "    else:\n",
    "        leafDict[hash(tree)] = dataFrame['Class'].value_counts()\n",
    "\n",
    "# Removes data values from hashed leaf dictionary\n",
    "def minus_leaf_dict_data(tree, dataFrame, leafDict):\n",
    "    # Update children of tree\n",
    "    if not tree.is_leaf:\n",
    "        \n",
    "        # Get new data split for child nodes\n",
    "        feature, operator, value = tree.name.split()\n",
    "        leftData,rightData  = split_data(dataFrame, feature, operator, value)\n",
    "        # Recure through all children\n",
    "        if((not leftData.empty) and not tree.children[0].right):\n",
    "            minus_leaf_dict_data(tree.children[0],leftData,leafDict)\n",
    "        if((not rightData.empty) and len(tree.children)>1):\n",
    "            minus_leaf_dict_data(tree.children[1],rightData,leafDict)\n",
    "        elif((not rightData.empty) and tree.children[0].right):\n",
    "            minus_leaf_dict_data(tree.children[0],rightData,leafDict)\n",
    "    else:\n",
    "        leafDict[hash(tree)] = leafDict[hash(tree)].subtract(dataFrame['Class'].value_counts(),fill_value = 0).sort_values(ascending = False)\n",
    "\n",
    "# Adds data values to hashed leaf dictionary        \n",
    "def plus_leaf_dict_data(tree, dataFrame, leafDict):\n",
    "    # Update children of tree\n",
    "    if not tree.is_leaf:\n",
    "        \n",
    "        # Get new data split for child nodes\n",
    "        feature, operator, value = tree.name.split()\n",
    "        leftData,rightData  = split_data(dataFrame, feature, operator, value)\n",
    "        # Recure through all children\n",
    "        if((not leftData.empty) and not tree.children[0].right):\n",
    "            plus_leaf_dict_data(tree.children[0],leftData,leafDict)\n",
    "        if((not rightData.empty) and len(tree.children)>1):\n",
    "            plus_leaf_dict_data(tree.children[1],rightData,leafDict)\n",
    "        elif((not rightData.empty) and tree.children[0].right):\n",
    "            plus_leaf_dict_data(tree.children[0],rightData,leafDict)\n",
    "    else:\n",
    "        leafDict[hash(tree)] = dataFrame['Class'].value_counts().add(leafDict[hash(tree)],fill_value = 0).sort_values(ascending = False)\n",
    "\n",
    "# Gets error of a sorted series (using most popular class)\n",
    "def series_error(series):\n",
    "    return series.sum() -  series.iloc[0] \n",
    "\n",
    "# Outputs error of series\n",
    "def check_dict_error(item):\n",
    "    if type(item) == pd.Series:\n",
    "        return series_error(item)\n",
    "    else:\n",
    "        return np.inf\n",
    "\n",
    "# Gets error of a hashed leaf dictionary\n",
    "def get_dict_error(leafDict):\n",
    "    error = 0\n",
    "    for key in leafDict.keys():\n",
    "        error += check_dict_error(leafDict[key])\n",
    "    return error\n",
    "\n",
    "# Outputs error of series\n",
    "def get_dict_size(item):\n",
    "    if type(item) == pd.Series:\n",
    "        return item.sum()\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def min_leaf(leafDict,n_min):\n",
    "    satisfies = True\n",
    "    for leafSize in leafDict.values():\n",
    "        if(get_dict_size(leafSize) < n_min):\n",
    "            satisfies = False\n",
    "    return satisfies\n",
    "    \n",
    "\n",
    "# Debugging function for error of a hashed leaf dictionary\n",
    "def get_each_dict_error(leafDict):\n",
    "    for key in leafDict.keys():\n",
    "        print(leafDict[key])\n",
    "        print(check_dict_error(leafDict[key]))\n",
    "\n",
    "# Exhaustively finds the local optimal data split of a node while keeping it's children\n",
    "def optimal_node_data_split_dict(node, dataFrame, alpha = 0.5, baseLineError = 1, n_min = 1): \n",
    "    # Gets children nodes of node\n",
    "    childNodes = node.children\n",
    "    \n",
    "    # Sets best error as error of current node\n",
    "    bestError = [error_value(node, dataFrame)*(1/baseLineError)]\n",
    "    \n",
    "    # Only runs on nodes \n",
    "    if(len(childNodes) != 1):\n",
    "        # Creates empty child nodes for lead nodes\n",
    "        if(len(childNodes) == 0):\n",
    "            leftNode = Node(\"\", right = False, checked = False)\n",
    "            rightNode = Node(\"\", right = True, checked = False)\n",
    "            newSplitCost = 1\n",
    "            \n",
    "        else:\n",
    "            leftNode = childNodes[0]\n",
    "            rightNode = childNodes[1]\n",
    "            newSplitCost = 0\n",
    "        # Adjust best error for complexity cost\n",
    "        bestError[0] -= alpha * newSplitCost\n",
    "        \n",
    "\n",
    "        \n",
    "        # Loop through all features\n",
    "        for feature in get_features(dataFrame):\n",
    "            \n",
    "            # Remove duplicate data points for splits in feature\n",
    "            values = dataFrame[feature].drop_duplicates().sort_values().reset_index(drop=True)\n",
    "            \n",
    "            # For every feature, create/reset left and right dictionary\n",
    "            left_leaf_dict = leaves_to_dict(leftNode)\n",
    "            right_leaf_dict = leaves_to_dict(rightNode)\n",
    "            \n",
    "            # Place all data points in right leaf dictionary\n",
    "            put_leaf_dict_data(rightNode, dataFrame, right_leaf_dict)\n",
    "            \n",
    "            # Loop through splits in feature\n",
    "            for i, point in enumerate(values[:-1]):\n",
    "                \n",
    "                # Get all points in between current split and previous split\n",
    "                samePoints = dataFrame.query('{feature} == {value}'.format(feature = feature,value = point))\n",
    "                \n",
    "                \n",
    "                # Remove points from right leaf dictionary\n",
    "                minus_leaf_dict_data(rightNode, samePoints, right_leaf_dict)\n",
    "\n",
    "                # Add points from left leaf dictionary\n",
    "                plus_leaf_dict_data(leftNode, samePoints, left_leaf_dict)\n",
    "                \n",
    "                \n",
    "                # Check if new split satisfies n_min\n",
    "                if(min_leaf(left_leaf_dict,n_min) and min_leaf(right_leaf_dict,n_min)):\n",
    "                    \n",
    "                    #Calculate error of split\n",
    "                    new_error = (get_dict_error(left_leaf_dict) + get_dict_error(right_leaf_dict))*(1/baseLineError)\n",
    "                    \n",
    "                    # Set new best split\n",
    "                    if(new_error < bestError[0]):\n",
    "                        bestError = [new_error,feature,\"<\",(1/2 * (values.iloc[i] + values.iloc[i+1]))]\n",
    "                        \n",
    "                        # For debugging purposes\n",
    "                        #print(bestError)\n",
    "        # Replace node if best new split is better than current\n",
    "        if(len(bestError) > 1):\n",
    "            # Create split node\n",
    "            bestErrorNode = Node('{feature} {operator} {value}'.format(feature = bestError[1],operator = bestError[2],value = bestError[3]), children = childNodes, checked = True)\n",
    "            \n",
    "            if(childNodes):\n",
    "                # Update children of replacement node at new decision point\n",
    "                update_tree(bestErrorNode,dataFrame)\n",
    "                bestErrorNode.checked = True\n",
    "            else:\n",
    "                # Create children at new decision point for nodes which were previously leaves\n",
    "                leftDataFrame,rightDataFrame = split_data(dataFrame,bestError[1],\"<\",bestError[3])\n",
    "                create_leaf(leftDataFrame,parent=bestErrorNode,right=False)\n",
    "                create_leaf(rightDataFrame,parent=bestErrorNode,right=True)\n",
    "                \n",
    "            # Replace old node with new node\n",
    "            replace_node(bestErrorNode, node)\n",
    "\n",
    "        else:\n",
    "            node.checked = True\n",
    "            bestErrorNode = node\n",
    "        \n",
    "        return bestErrorNode\n",
    "        # If checking to update node here, add one to complexity when splitting on leaf\n",
    "    else:\n",
    "        # Runs delete node when only one child node exists\n",
    "        return delete_split(node, dataFrame, alpha, baseLineError)\n",
    "    \n",
    "#######\n",
    "\n",
    "def replace_node(newNode,oldNode):\n",
    "    # Add new node to tree\n",
    "    newNode.parent = oldNode.parent\n",
    "                \n",
    "    # Get the position of the node relative to the parent\n",
    "    newNode.right = oldNode.right\n",
    "            \n",
    "    # Remove original node from tree\n",
    "    oldNode.parent = None\n",
    "                \n",
    "    # Reset left positioned nodes\n",
    "    place_left_node(newNode)\n",
    "                \n",
    "    #Uncheck parents for improvement\n",
    "    uncheck_parents(newNode)\n",
    "\n",
    "def place_left_node(node):\n",
    "    if (not node.right and node.parent):\n",
    "        if(len(node.parent.children)>1):\n",
    "            node.parent.children = [node.parent.children[1],node.parent.children[0]]\n",
    "    \n",
    "# Create new split at given node\n",
    "def optimal_split(node, dataFrame, alpha = 0.5, baseLineError = 1, n_min = 1):\n",
    "    \n",
    "    \n",
    "    # Create new optimal split if it does not violate minimum number of data points\n",
    "    if(len(dataFrame.index) >= n_min * 2):\n",
    "        # Create parallel split\n",
    "        newNode = optimal_node_data_split_dict(node, dataFrame, alpha = alpha, baseLineError = baseLineError, n_min = n_min)\n",
    "        # change node to decision\n",
    "        return newNode\n",
    "    else:\n",
    "        return node\n",
    "\n",
    "# Updates tree with new data values\n",
    "def update_tree(tree, dataFrame):\n",
    "    # Reset checked flag\n",
    "    tree.checked = False\n",
    "    \n",
    "    # Update children of tree\n",
    "    if not tree.is_leaf:\n",
    "        \n",
    "        # Get new data split for child nodes\n",
    "        feature, operator, value = tree.name.split()\n",
    "        leftData,rightData  = split_data(dataFrame, feature, operator, value)\n",
    "        \n",
    "        # Recure through all children\n",
    "        if((not leftData.empty) and not tree.children[0].right):\n",
    "            update_tree(tree.children[0],leftData)\n",
    "        if((not rightData.empty) and len(tree.children)>1):\n",
    "            update_tree(tree.children[1],rightData)\n",
    "        elif((not rightData.empty) and tree.children[0].right):\n",
    "            update_tree(tree.children[0],rightData)\n",
    "    else:\n",
    "        # debugging\n",
    "        if(len(dataFrame.index) == 0):\n",
    "            print(\" No items at tree: \", tree)\n",
    "        \n",
    "        \n",
    "        # Update leaf for new data points\n",
    "        Class = dataFrame['Class'].value_counts().first_valid_index()\n",
    "        tree.error = calculate_combined_error(dataFrame, Class)\n",
    "        tree.size = len(dataFrame.index)\n",
    "        tree.accuracy =  (dataFrame['Class'].value_counts().iloc[0]/len(dataFrame.index)).round(3)\n",
    "        tree.name = \"class = {Class}, accuracy = {accuracy}, size = {size} error = {error}\".format(Class=Class,accuracy=tree.accuracy,size = tree.size, error = tree.error)\n",
    "        tree.Class =  Class\n",
    "\n",
    "    \n",
    "# Improve tree by replacing current split with one of it's children\n",
    "def delete_split(node, dataFrame, alpha = 0.5, baseLineError = 1):\n",
    "    # Set default node to original node\n",
    "    newNode = node\n",
    "    \n",
    "    # Check if node has children\n",
    "    if not node.is_leaf:\n",
    "        \n",
    "        # If multiple children\n",
    "        if len(node.children) > 1:\n",
    "            \n",
    "            # Try replacing with left child\n",
    "            leftNode = node.children[0]\n",
    "            \n",
    "            # Try replacing with right child\n",
    "            rightNode = node.children[1]\n",
    "            \n",
    "            \n",
    "            # Create leaf dictionaries for left and right child nodes\n",
    "            left_leaf_dict = leaves_to_dict(leftNode)\n",
    "            right_leaf_dict = leaves_to_dict(rightNode)\n",
    "            \n",
    "            # Place data in left and right leaf dictionaries\n",
    "            put_leaf_dict_data(leftNode, dataFrame, left_leaf_dict)\n",
    "            put_leaf_dict_data(rightNode, dataFrame, right_leaf_dict)\n",
    "            \n",
    "            # Get loss of  left and right leaf dictionaries\n",
    "            rightLoss = dict_loss_function(rightNode, right_leaf_dict, alpha, baseLineError)\n",
    "            leftLoss = dict_loss_function(leftNode, left_leaf_dict, alpha, baseLineError)\n",
    "            \n",
    "            # Get loss of original node\n",
    "            currentLoss = loss_function(node, dataFrame, alpha, baseLineError)\n",
    "            \n",
    "            improved = False\n",
    "            \n",
    "            # Replace old node with left or right node if they have lower loss\n",
    "            if leftLoss < rightLoss:\n",
    "                if leftLoss < currentLoss:\n",
    "                    newNode = leftNode\n",
    "                    improved = True\n",
    "            else:\n",
    "                if rightLoss < currentLoss:\n",
    "                    newNode = rightNode\n",
    "                    improved = True\n",
    "            \n",
    "            \n",
    "            # Place replacement node in the original tree\n",
    "            if improved:\n",
    "                \n",
    "                # Replace node with new node\n",
    "                replace_node(newNode,node)\n",
    "                \n",
    "                # Update nodes\n",
    "                update_tree(newNode, dataFrame)\n",
    "            else:\n",
    "                # Check non-improved \n",
    "                node.checked = True\n",
    "                \n",
    "        # Single child\n",
    "        else:\n",
    "            newNode = node.children[0]\n",
    "            \n",
    "    return newNode\n",
    "\n",
    "# Creates a new split at a leaf\n",
    "# Buffer function to reduce potential unnecessary calculations\n",
    "def create_split(node, dataFrame, alpha = 0.5, baseLineError = 1, n_min = 1):\n",
    "    \n",
    "    newNode = node\n",
    "    \n",
    "    if node.is_leaf:\n",
    "        \n",
    "        # Only creates leaf if accuracy cannot be improved or improved node would violate minimum data count at leaves\n",
    "        if node.error > 0 and len(dataFrame.index) >= n_min * 2:\n",
    "            \n",
    "            newNode = optimal_split(node, dataFrame, alpha, baseLineError, n_min)\n",
    "        else:\n",
    "            # Checks the leaf if it cannot be improved\n",
    "            node.checked = True\n",
    "    \n",
    "    # Incase non-leaves are run through create split\n",
    "    else:\n",
    "        newNode = optimal_split(node, dataFrame, alpha, baseLineError, n_min)\n",
    "        \n",
    "    return newNode\n",
    "            \n",
    "# Returns random unchecked node from tree\n",
    "def get_random_node(tree):\n",
    "    availableNodes = [node for node in PreOrderIter(tree) if not node.checked]\n",
    "    if availableNodes:\n",
    "        return random.choice(availableNodes)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Gets root of node\n",
    "# If no root, returns node\n",
    "def get_root(node):\n",
    "    return node.root\n",
    "\n",
    "# Calculates baseline error of a dataset\n",
    "def calculate_baseline_error(dataFrame):\n",
    "    return len(dataFrame.index) - dataFrame[\"Class\"].value_counts().iloc[0]\n",
    "\n",
    "# Unchecks all parents of a node recursively\n",
    "def uncheck_parents(node):\n",
    "    if node.parent:\n",
    "        node.parent.checked = False\n",
    "        uncheck_parents(node.parent)\n",
    "\n",
    "# Main loop for creating Optimal Classification Trees\n",
    "def random_node_modification(tree, dataFrame, n_min = 1, D_max = 5, alpha = 0.5):\n",
    "    \n",
    "    # Calculate baseline error of data\n",
    "    baseLineError = calculate_baseline_error(dataFrame)\n",
    "    \n",
    "    # Loops through while unchecked nodes are in the tree\n",
    "    while get_random_node(tree):\n",
    "        \n",
    "        # Pick random unchecked node for modification\n",
    "        node = get_random_node(tree)\n",
    "            \n",
    "        # Get data frame at specific node\n",
    "        dataFrameNode = data_values(node,dataFrame)\n",
    "        # Runs update (parallel) split and delete split on decision nodes\n",
    "        if not node.is_leaf:\n",
    "            \n",
    "            # Run update split\n",
    "            node = optimal_split(node, dataFrameNode, alpha, baseLineError, n_min)\n",
    "            \n",
    "            # Run delete split\n",
    "            node = delete_split(node, dataFrameNode, alpha, baseLineError)\n",
    "        else:\n",
    "            \n",
    "            # Only creates new split if leaf is not at max depth\n",
    "            if node.depth < D_max:\n",
    "                node = create_split(node, dataFrameNode, alpha, baseLineError, n_min)\n",
    "            else:\n",
    "                node.checked = True\n",
    "                \n",
    "        # Reset the root if the node chosen for modification is the root\n",
    "        if (node == get_root(node)):\n",
    "            tree = node\n",
    "        \n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds best local optimum tree with given hyperparameters and tree count\n",
    "def best_local_optimum_tree(dataFrame, n = 1, n_min = 1, D_max = 5, alpha = 0.5):\n",
    "    \n",
    "    # Initialse baseline\n",
    "    baseLineError = calculate_baseline_error(dataFrame)\n",
    "    \n",
    "    # Intiliase error for baseline leaf\n",
    "    optimalTree = create_leaf(dataFrame)\n",
    "    bestLoss = loss_function(optimalTree, dataFrame, alpha, baseLineError)\n",
    "    # Loop through number of trees\n",
    "    for i in range(0,n):\n",
    "        \n",
    "        # Create random tree\n",
    "        startingTree = random_tree(dataFrame, get_features(dataFrame), remainingDepth = D_max, n_min = n_min)\n",
    "        \n",
    "        # Run optimal tree function to find local optimum tree\n",
    "        localOptimalTree = random_node_modification(startingTree,dataFrame,alpha = alpha, D_max = D_max, n_min = n_min)\n",
    "        \n",
    "        # Get loss of local optimum tree\n",
    "        localLoss = loss_function(localOptimalTree, dataFrame, alpha, baseLineError)\n",
    "        \n",
    "        # Replace best tree with new local optimum tree if better\n",
    "        if(localLoss < bestLoss):\n",
    "            \n",
    "            optimalTree = localOptimalTree\n",
    "            \n",
    "            # Update best loss\n",
    "            bestLoss = localLoss\n",
    "    \n",
    "    return optimalTree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
