{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "from anytree import Node, RenderTree, PreOrderIter\n",
    "import anytree\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "print(sys.getrecursionlimit())\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Test data 2:\n",
    "\n",
    "classes = [0, 1]\n",
    "feature_names = [\"x\",\"y\",\"z\",\"class\"]\n",
    "class_attributes = [[10,12,8],[12,8,10],[8,10,12]]\n",
    "\n",
    "# Creates random data with class, class atrribute 2d array and number of datapoints per class\n",
    "def create_random_data(classes, class_attributes,n):\n",
    "    data_points = []\n",
    "    for i in range(0,n):\n",
    "        for class_type in classes:\n",
    "            new_data_point = []\n",
    "            for attribute in class_attributes[class_type]:\n",
    "                new_data_point.append(random.gauss(attribute,1.5))\n",
    "            new_data_point.append(class_type)\n",
    "            data_points.append(new_data_point)\n",
    "    return data_points\n",
    "    \n",
    "# Create test data and transform it into a data frame\n",
    "data = create_random_data(classes, class_attributes,100)\n",
    "X = to_data_frame(data, feature_names)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "# creates a data frame from a list of lists\n",
    "def to_data_frame(data, feature_names):\n",
    "    return pd.DataFrame(data, columns = feature_names)\n",
    "\n",
    "#split data into decision sets\n",
    "def split_data(feature, operator, value, dataFrame):\n",
    "    try:\n",
    "        leftDataFrame = dataFrame.query('{feature} {operator} {value}'.format(feature = feature, operator = operator, value = str(value)))\n",
    "        rightDataFrame = dataFrame[~dataFrame.isin(leftDataFrame)].dropna().reset_index(drop=True)\n",
    "        leftDataFrame.reset_index(drop=True,inplace=True)\n",
    "        return leftDataFrame, rightDataFrame\n",
    "    except Exception as e:\n",
    "        print(e, feature, operator, value)\n",
    "        return None\n",
    "\n",
    "# gets all features of the dataset, removing class\n",
    "def get_features(dataFrame):\n",
    "    features = []\n",
    "    for column in dataFrame.columns:\n",
    "        if column != \"Class\":\n",
    "            features.append(column)\n",
    "    return features\n",
    "\n",
    "# Gets classes that are available in a data frame\n",
    "def get_classes(dataFrame):\n",
    "    return dataFrame[\"Class\"].unique()\n",
    "\n",
    "# untested\n",
    "def get_classes_multi(dataFrame, *dataFrames):\n",
    "    combinedDataFrame = reduce(lambda left,right: pd.merge(left,right,on='name'), [dataFrame] + [dataFrames])\n",
    "    return get_classes(combinedDataFrame)\n",
    "    \n",
    "\n",
    "\n",
    "def create_simulated_data(classes, n, d):\n",
    "    data_points = []\n",
    "    for i in range(0,n):\n",
    "        newClass = np.random.binomial(1,0.5)\n",
    "        new_data_point = []\n",
    "        if(newClass == 0):\n",
    "            # x axis\n",
    "            new_data_point.append(np.random.uniform(0,0.5,1)[0].round(3))\n",
    "            # y axis\n",
    "            new_data_point.append(np.random.uniform(0,0.5,1)[0].round(3))\n",
    "                \n",
    "        else:\n",
    "            new_data_point.append(np.random.uniform(0,1,1)[0].round(3))\n",
    "            if(new_data_point[0] <= 0.5):\n",
    "                new_data_point.append(np.random.uniform(.51,1,1)[0].round(3))\n",
    "            else:\n",
    "                new_data_point.append(np.random.uniform(0,1,1)[0].round(3))\n",
    "        new_data_point += [1 for i in range(0,d-2)]\n",
    "        new_data_point.append(newClass)\n",
    "        data_points.append(new_data_point)\n",
    "    return data_points\n",
    "\n",
    "\n",
    "n = 100\n",
    "d = 3\n",
    "simulated = create_simulated_data([0,1],n,d)\n",
    "simulatedData = to_data_frame(simulated, [\"x_{n}\".format(n = n) for n in range(0,d)]+[\"Class\"])\n",
    "test_data = pd.read_csv('Iris.csv')\n",
    "del test_data[\"Id\"]\n",
    "#test_data.plot(x=\"SepalLengthCm\",y=\"SepalWidthCm\", hue=\"Species\",kind=\"scatter\")\n",
    "#plt.show()\n",
    "\n",
    "test_data.rename(columns={'Species': 'Class'},inplace=\"True\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the error of a dataframe given a target class\n",
    "def calculate_combined_error(dataFrame, targetClass):\n",
    "    return len(dataFrame.query(\"Class != @targetClass\").index)\n",
    "\n",
    "# Calculates the error of a dataframe using the most popular class\n",
    "def popular_error(dataFrame):\n",
    "    return calculate_combined_error(dataFrame, dataFrame[\"Class\"].value_counts().first_valid_index())\n",
    "\n",
    "# Calculates the error value of how well the tree fits the data\n",
    "# Input: Tree, Dataframe\n",
    "# Recursive function\n",
    "def error_value(tree, dataFrame):\n",
    "    # misclassification error\n",
    "    error = 0\n",
    "    \n",
    "    if not tree.is_leaf:\n",
    "        \n",
    "        # split data by decision\n",
    "        feature, operator, value = tree.name.split()\n",
    "        leftData,rightData  = split_data(feature, operator, value, dataFrame)\n",
    "        \n",
    "        # recure through left and right nodes\n",
    "        if((not leftData.empty) and not tree.children[0].right):\n",
    "            error += error_value(tree.children[0],leftData)\n",
    "        if((not rightData.empty) and len(tree.children)>1):\n",
    "            error += error_value(tree.children[1],rightData)\n",
    "        elif((not rightData.empty) and tree.children[0].right):\n",
    "            error += error_value(tree.children[0],rightData)\n",
    "    else:\n",
    "        error = tree.error\n",
    "        \n",
    "    return error\n",
    "\n",
    "\n",
    "\n",
    "# Calculates the penalizing value for the complexity of the tree\n",
    "# Input: Tree\n",
    "# Recursive function\n",
    "def complexity(tree):\n",
    "    length = 0\n",
    "    if not tree.is_leaf:\n",
    "        # increase complexity by number of splits in the tree\n",
    "        length += 1\n",
    "        for child in tree.children:\n",
    "            length += complexity(child)\n",
    "    return length\n",
    "\n",
    "\n",
    "# calculates the loss function for the tree and the respective data\n",
    "def loss_function(tree, dataFrame, alpha = 0.5,baseLineError = 1):\n",
    "    if baseLineError <= 0:\n",
    "        baseLineError = 1\n",
    "    return (1/baseLineError) * error_value(tree, dataFrame) + alpha * complexity(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SepalLengthCm < 5.8, Left, False\n",
      "├── PetalWidthCm < 1.2, Left, False\n",
      "│   ├── PetalLengthCm < 1.5, Left, False\n",
      "│   │   ├── class = Iris-setosa, accuracy = 1.0, size = 22 error = 0, Left, False\n",
      "│   │   └── class = Iris-setosa, accuracy = 0.771, size = 35 error = 8, Right, False\n",
      "│   └── SepalLengthCm < 5.6, Right, False\n",
      "│       ├── class = Iris-versicolor, accuracy = 0.833, size = 6 error = 1, Left, False\n",
      "│       └── class = Iris-versicolor, accuracy = 0.8, size = 10 error = 2, Right, False\n",
      "└── PetalLengthCm < 4.6, Right, False\n",
      "    ├── SepalWidthCm < 2.7, Left, False\n",
      "    │   ├── class = Iris-versicolor, accuracy = 1.0, size = 4 error = 0, Left, False\n",
      "    │   └── class = Iris-versicolor, accuracy = 0.917, size = 12 error = 1, Right, False\n",
      "    └── SepalWidthCm < 3.2, Right, False\n",
      "        ├── class = Iris-virginica, accuracy = 0.756, size = 45 error = 11, Left, False\n",
      "        └── class = Iris-virginica, accuracy = 0.812, size = 16 error = 3, Right, False\n"
     ]
    }
   ],
   "source": [
    "# Create a leaf\n",
    "# Uses most populous class in available data frame\n",
    "def create_leaf(dataFrame,parent=None,right=False):\n",
    "    \n",
    "    if not dataFrame.empty:\n",
    "        \n",
    "        # Get the most populous class\n",
    "        Class = dataFrame['Class'].value_counts().first_valid_index()\n",
    "\n",
    "        # Get accuracy of class\n",
    "        accuracy = (dataFrame['Class'].value_counts().iloc[0]/len(dataFrame.index)).round(3)\n",
    "        error = calculate_combined_error(dataFrame, Class)\n",
    "        size = len(dataFrame.index)\n",
    "        \n",
    "        # Create Node using parent node\n",
    "        leaf = Node(\"class = {Class}, accuracy = {accuracy}, size = {size} error = {error}\".format(Class=Class,accuracy=accuracy,size = size, error = error),parent=parent, Class = Class, accuracy = accuracy, error = error,size = size, right = right, checked = False)\n",
    "\n",
    "        return leaf\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# recursive function for creating trees\n",
    "def create_tree(dataFrame, features, parent = None, remainingLength = 0, right = False, operators = [\"<\"], n_min = 1):\n",
    "    \n",
    "    # create node with splits\n",
    "    if(remainingLength > 0 and len(dataFrame.index) >= n_min * 2):\n",
    "        \n",
    "        \n",
    "        leftDataFrame, rightDataFrame = pd.DataFrame(), pd.DataFrame()\n",
    "        # Restrict possible dataframes by minimum data points\n",
    "        while len(leftDataFrame.index) < n_min or len(rightDataFrame.index) < n_min:\n",
    "            # split decision\n",
    "            ############################################\n",
    "            # Pick random feature and operator\n",
    "            feature, operator = random.choice(features), random.choice(operators)\n",
    "            # Choose random value in available feature\n",
    "            value = random.choice(dataFrame[feature]).round(3)\n",
    "            ############################################\n",
    "            # Create decision node\n",
    "\n",
    "            \n",
    "\n",
    "            # Split dataset on decision\n",
    "            leftDataFrame, rightDataFrame = split_data(feature, operator, value, dataFrame)\n",
    "            \n",
    "        # Create decision node\n",
    "        tree = Node('{feature} {operator} {value}'.format(feature = feature,operator = operator,value = value),parent = parent, right = right, checked = False)\n",
    "        \n",
    "        # create child nodes of decision node\n",
    "        if(not leftDataFrame.empty):\n",
    "            create_tree(leftDataFrame,features,tree,remainingLength=remainingLength-1,right=False, n_min = n_min)\n",
    "        if(not rightDataFrame.empty):\n",
    "            create_tree(rightDataFrame,features,tree,remainingLength=remainingLength-1,right=True, n_min = n_min)\n",
    "    # Create a class node when at max length or no possible splits remaining\n",
    "    else:\n",
    "        # create leaf\n",
    "        tree = create_leaf(dataFrame, parent, right)\n",
    "    return tree\n",
    "\n",
    "# prints the tree in ascii\n",
    "def print_tree(tree):\n",
    "    for pre, fill, node in RenderTree(tree):\n",
    "        print(\"%s%s, %s, %s\" % (pre, node.name,\"Left\" if not node.right else \"Right\", node.checked))\n",
    "        \n",
    "# create test tree\n",
    "finalTree = create_tree(test_data, get_features(test_data), remainingLength = 3, n_min = 2)\n",
    "print_tree(finalTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trims the dataset to appropriate data for the node\n",
    "# Recurses from bottom to top\n",
    "def data_values(node, dataFrame,right = None):\n",
    "    \n",
    "    # trim data starting from parent value\n",
    "    if node.parent:\n",
    "        dataFrame = data_values(node.parent,dataFrame,node.right)\n",
    "        \n",
    "    # if data is being split at node and the node has a split\n",
    "    # Split data according to next node direction\n",
    "    if right != None and node.children:\n",
    "        \n",
    "        feature, operator, value = node.name.split()\n",
    "        return split_data(feature, operator, value, dataFrame)[int(right)]\n",
    "    # If leaf or not splitting data at node\n",
    "    # Return data at that node\n",
    "    else:\n",
    "        return dataFrame\n",
    "\n",
    "# Verifies if all leaves in a tree have the minimum amount of data points\n",
    "def verify_minimum_leaves(tree, n_min = 1):\n",
    "    truth = True\n",
    "    if tree.is_leaf:\n",
    "        if tree.size < n_min:\n",
    "            truth = False\n",
    "    else:\n",
    "        for child in tree.children:\n",
    "            truth = truth == verify_minimum_leaves(child, n_min)\n",
    "    \n",
    "    return truth\n",
    "\n",
    "# Exhaustively finds the local optimal data split of a node while keeping it's children\n",
    "def optimal_node_data_split(node, dataFrame, operators=[\"<\"], n_min = 1, alpha = 0.5, baseLineError = 1):\n",
    "    # Gets deep copies of child nodes - Keeps original child nodes unchanged\n",
    "    childNodes = [copy.deepcopy(childNode) for childNode in node.children]\n",
    "    \n",
    "    # Set starting error to infinity\n",
    "    lowestError = [np.inf,\"0\",\"==\",\"0\"]#pd.DataFrame(columns=[\"Gini Value\",\"Feature\",\"Operator\",\"Value\"])\n",
    "    \n",
    "    # loops through all data points\n",
    "    for feature in get_features(dataFrame):\n",
    "        \n",
    "        # sort values in feature in ascending order\n",
    "        values = dataFrame[feature].drop_duplicates().sort_values().reset_index(drop=True)\n",
    "        \n",
    "        # Gets midwayt point of all sorted data values\n",
    "        for i in range(0, len(values)-1):\n",
    "            point = (1/2 * (values.iloc[i] + values.iloc[i+1])).round(3)\n",
    "            \n",
    "            newError = 0\n",
    "            \n",
    "            # loops through all possible operators (in case of mix of discrete and continuous data)\n",
    "            for operator in operators:\n",
    "                \n",
    "                # Create a potential replacement node \n",
    "                newNode = Node('{feature} {operator} {value}'.format(feature = feature,operator = operator,value = point), children = childNodes, checked = False)\n",
    "                if(childNodes):\n",
    "                    # Update children of replacement node at new decision point\n",
    "                    update_tree(newNode,dataFrame)\n",
    "                else:\n",
    "                    # Create children at new decision point for nodes which were previously leaves\n",
    "                    leftDataFrame,rightDataFrame = split_data(feature,operator,point,dataFrame)\n",
    "                    create_leaf(leftDataFrame,parent=newNode,right=False)\n",
    "                    create_leaf(rightDataFrame,parent=newNode,right=True)\n",
    "                    \n",
    "                # Check if new tree meets minimum number of data points\n",
    "                if(verify_minimum_leaves(newNode, n_min)):\n",
    "                    \n",
    "                    # Calculate new error for tree\n",
    "                    newError = loss_function(newNode,dataFrame,alpha,baseLineError)\n",
    "                    \n",
    "                    # Replace previous best replacement node if new replacement is better\n",
    "                    if newError < lowestError[0]:\n",
    "                        lowestError = [newError,copy.deepcopy(newNode)]\n",
    "                        print(lowestError)\n",
    "                    #giniValues.append([newGiniValue,feature,operator,point])\n",
    "    \n",
    "    # Return best node\n",
    "    return lowestError[1]\n",
    "    \n",
    "#######\n",
    "\n",
    "def place_left_node(node):\n",
    "    if (not node.right and node.parent):\n",
    "        if(len(node.parent.children)>1):\n",
    "            node.parent.children = [node.parent.children[1],node.parent.children[0]]\n",
    "    \n",
    "# Create new split at given node\n",
    "def optimal_split(node, dataFrame, n_min = 1, alpha = 0.5, baseLineError = 1):\n",
    "    \n",
    "    # Extract set of features\n",
    "    features = get_features(dataFrame)\n",
    "    \n",
    "    # Create new optimal split if it does not violate minimum number of data points\n",
    "    if(len(dataFrame.index)) >= n_min * 2:\n",
    "        \n",
    "        # Create parallel split\n",
    "        tree = optimal_node_data_split(node, dataFrame, n_min = n_min, alpha = alpha, baseLineError = baseLineError)\n",
    "        # Add new split node to tree\n",
    "        parent = node.parent\n",
    "        right = node.right\n",
    "        tree.right = right\n",
    "        tree.parent = parent\n",
    "        \n",
    "        # Remove old split node from tree\n",
    "        node.parent = None\n",
    "        # Place left nodes back on left\n",
    "        place_left_node(tree)\n",
    "\n",
    "\n",
    "        # change node to decision\n",
    "        return tree\n",
    "    else:\n",
    "        return node\n",
    "\n",
    "# Updates tree with new data values\n",
    "def update_tree(tree, dataFrame, n_min = 1):\n",
    "    # Reset checked flag\n",
    "    tree.checked = False\n",
    "    \n",
    "    # Update children of tree\n",
    "    if not tree.is_leaf:\n",
    "        \n",
    "        # Get new data split for child nodes\n",
    "        feature, operator, value = tree.name.split()\n",
    "        leftData,rightData  = split_data(feature, operator, value, dataFrame)\n",
    "        \n",
    "        # Recure through all children\n",
    "        if((not leftData.empty) and not tree.children[0].right):\n",
    "            update_tree(tree.children[0],leftData)\n",
    "        if((not rightData.empty) and len(tree.children)>1):\n",
    "            update_tree(tree.children[1],rightData)\n",
    "        elif((not rightData.empty) and tree.children[0].right):\n",
    "            update_tree(tree.children[0],rightData)\n",
    "    else:\n",
    "        # Update leaf for new data points\n",
    "        Class = dataFrame['Class'].value_counts().first_valid_index()\n",
    "        tree.error = calculate_combined_error(dataFrame, Class)\n",
    "        tree.size = len(dataFrame.index)\n",
    "        tree.accuracy =  (dataFrame['Class'].value_counts().iloc[0]/len(dataFrame.index)).round(3)\n",
    "        tree.name = \"class = {Class}, accuracy = {accuracy}, size = {size} error = {error}\".format(Class=Class,accuracy=tree.accuracy,size = tree.size, error = tree.error)\n",
    "        tree.Class =  Class\n",
    "\n",
    "    \n",
    "# Delete the split at the given node\n",
    "def delete_split(node, dataFrame, alpha = 0.5, baseLineError = 1):\n",
    "    # Set default node to original node\n",
    "    newNode = node\n",
    "    \n",
    "    # Check if node has children\n",
    "    if node.children:\n",
    "        \n",
    "        # If multiple children\n",
    "        if len(node.children) > 1:\n",
    "            \n",
    "            # Try replacing with left child\n",
    "            leftNode = copy.deepcopy(node.children[0])\n",
    "            \n",
    "            # Try replacing with right child\n",
    "            rightNode = copy.deepcopy(node.children[1])\n",
    "            \n",
    "            \n",
    "            # Get loss of original node\n",
    "            currentLoss = loss_function(node, dataFrame, alpha, baseLineError)\n",
    "            \n",
    "            # Update children of left and right node with new data\n",
    "            update_tree(leftNode,dataFrame)           \n",
    "            update_tree(rightNode,dataFrame)\n",
    "            \n",
    "            # Get loss of new updated left and right trees\n",
    "            rightLoss = loss_function(rightNode, dataFrame, alpha, baseLineError)\n",
    "            leftLoss = loss_function(leftNode, dataFrame, alpha, baseLineError)\n",
    "            \n",
    "            # Replace old node with left or right node if they have lower loss\n",
    "            if leftLoss < rightLoss:\n",
    "                if leftLoss < currentLoss:\n",
    "                    newNode = copy.deepcopy(leftNode)\n",
    "            else:\n",
    "                if rightLoss < currentLoss:\n",
    "                    newNode = copy.deepcopy(rightNode)\n",
    "            \n",
    "            \n",
    "            \n",
    "            if newNode != node:\n",
    "                \n",
    "                # Add new node to tree\n",
    "                newNode.parent = node.parent\n",
    "                \n",
    "                \n",
    "                if newNode.parent == None:\n",
    "                    update_tree(newNode,dataFrame)\n",
    "                \n",
    "                # get the position of the node relative to the parent\n",
    "                newNode.right = node.right\n",
    "                \n",
    "                # Remove original node from tree\n",
    "                node.parent = None\n",
    "                \n",
    "                # Reset left positioned nodes\n",
    "                place_left_node(newNode)\n",
    "                \n",
    "        # Single child\n",
    "        else:\n",
    "            newNode = node.children[0]\n",
    "            \n",
    "    return newNode\n",
    "\n",
    "# Create a new split at the node\n",
    "def update_split(node, dataFrame, n_min = 1, alpha = 0.5, baseLineError = 1):\n",
    "    # replace previous split with new optimal split\n",
    "    return optimal_split(node,dataFrame, n_min, alpha, baseLineError)\n",
    "\n",
    "# Creates a new split at a leaf\n",
    "def create_split(node, dataFrame, n_min = 1, alpha = 0.5, baseLineError = 1):\n",
    "    newNode = node\n",
    "    if node.is_leaf:\n",
    "        \n",
    "        # Only creates leaf if accuracy cannot be improved or improved node would violate minimum data count at leaves\n",
    "        if node.accuracy < 1 and node.size >= n_min * 2:\n",
    "            \n",
    "            newNode = optimal_split(node, dataFrame, alpha, n_min, baseLineError)\n",
    "    \n",
    "    # Incase non-leaves are run through create split\n",
    "    else:\n",
    "        newNode = optimal_split(node, dataFrame, alpha, n_min, baseLineError)\n",
    "    return newNode\n",
    "            \n",
    "# Returns random unchecked node from tree\n",
    "def get_random_node(tree):\n",
    "    availableNodes = [node for node in PreOrderIter(tree) if not node.checked]\n",
    "    #availableNodes = [tree.root]\n",
    "    if availableNodes:\n",
    "        return random.choice(availableNodes)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Gets root of node\n",
    "# If no root, returns node\n",
    "def get_root(node):\n",
    "    if(node.root):\n",
    "        return node.root\n",
    "    else:\n",
    "        return node\n",
    "\n",
    "# Calculates baseline error of a dataset\n",
    "def calculate_baseline_error(dataFrame):\n",
    "    return 1 - dataFrame[\"Class\"].value_counts().iloc[0]/len(dataFrame.index)\n",
    "\n",
    "# Unchecks all parents of a node recursively\n",
    "def uncheck_parents(node):\n",
    "    if node.parent:\n",
    "        node.parent.checked = False\n",
    "        uncheck_parents(node.parent)\n",
    "\n",
    "# Replaces a tree with a deep copy of a tree from a given node and unchecks parents of given node\n",
    "def replace_tree(newNode):\n",
    "    uncheck_parents(newNode)\n",
    "    return copy.deepcopy(get_root(newNode)), True\n",
    "\n",
    "# Main loop for creating Optimal Classification Trees\n",
    "def random_node_modification(tree, dataFrame, n_min = 1, D_max = 5, alpha = 0.5):\n",
    "    \n",
    "    # Calculate baseline error of data\n",
    "    baseLineError = calculate_baseline_error(dataFrame)\n",
    "    \n",
    "    # Loops through while unchecked nodes are in the tree\n",
    "    while get_random_node(tree):\n",
    "        \n",
    "        # Set improvement check\n",
    "        improvement = False\n",
    "        \n",
    "        # Pick random unchecked node for modification\n",
    "        node = get_random_node(tree)\n",
    "        \n",
    "        # Get loss of picked node\n",
    "        loss = loss_function(node, dataFrame, alpha, baseLineError)\n",
    "        \n",
    "        # Get data frame at specific node\n",
    "        dataFrameNode = data_values(node,dataFrame)\n",
    "        \n",
    "        # Runs update (parallel) split and delete split on decision nodes\n",
    "        if not node.is_leaf:\n",
    "            \n",
    "            # Creates deep copy of node to improve\n",
    "            testNode = copy.deepcopy(node)\n",
    "            \n",
    "            # Tries replacing node with one of it's children\n",
    "            newNode = delete_split(testNode, dataFrameNode, alpha, baseLineError)\n",
    "            \n",
    "            # Calculates loss for new updated tree\n",
    "            newLoss = loss_function(newNode,dataFrame, alpha, baseLineError)\n",
    "            \n",
    "            # Replaces original node if new node is better\n",
    "            if newLoss < loss:\n",
    "                \n",
    "                tree, improvement =  replace_tree(newNode)\n",
    "                \n",
    "                # Update loss in case optimal split overrides\n",
    "                loss = loss_function(newNode, dataFrame, alpha, baseLineError)\n",
    "            \n",
    "            # Creates deep copy of node to improve\n",
    "            testNode = copy.deepcopy(node)\n",
    "            \n",
    "            # Tries replacing node with a parallel split node\n",
    "            newNode = update_split(testNode, dataFrameNode, n_min, alpha, baseLineError)\n",
    "            \n",
    "            # Calculates loss for new updated tree\n",
    "            newLoss = loss_function(newNode,dataFrame, alpha, baseLineError)\n",
    "            \n",
    "            # Replaces original node if new node is better\n",
    "            if newLoss < loss:\n",
    "                \n",
    "                tree, improvement =  replace_tree(newNode)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # Only creates new split if leaf is not at max depth\n",
    "            if node.depth < D_max:\n",
    "                \n",
    "                # Creates deep copy of node to improve\n",
    "                testNode = copy.deepcopy(node)\n",
    "                \n",
    "                # Tries creating new node to replace leaf\n",
    "                newNode = create_split(testNode, dataFrameNode, n_min, alpha, baseLineError)\n",
    "                \n",
    "                # Calculates loss for new updated tree\n",
    "                newLoss = loss_function(newNode, dataFrame, alpha, baseLineError)\n",
    "                \n",
    "                # Replaces original node if new node is better\n",
    "                if newLoss < loss:\n",
    "                    \n",
    "                    tree, improvement =  replace_tree(newNode)\n",
    "        \n",
    "        # Check the node if not improved\n",
    "        if not improvement:\n",
    "            node.checked = True\n",
    "        \n",
    "        # Reset Improvement check\n",
    "        improvement = False\n",
    "        \n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loop  0 : \n",
      "Baseline Error:  0.6666666666666667\n",
      "PetalWidthCm < 1.1, Left, False\n",
      "├── SepalLengthCm < 5.5, Left, False\n",
      "│   ├── class = Iris-setosa, accuracy = 0.938, size = 48 error = 3, Left, False\n",
      "│   └── class = Iris-setosa, accuracy = 0.556, size = 9 error = 4, Right, False\n",
      "└── SepalLengthCm < 6.3, Right, False\n",
      "    ├── class = Iris-versicolor, accuracy = 0.69, size = 42 error = 13, Left, False\n",
      "    └── class = Iris-virginica, accuracy = 0.725, size = 51 error = 14, Right, False\n",
      "New loop, current loss:  52.49999999999999\n",
      "Chosen Node: Node('/PetalWidthCm < 1.1/SepalLengthCm < 6.3', checked=False, right=True)  Loss at node:  40.99999999999999\n",
      "Depth of node:  1\n",
      "trying delete\n",
      "Node has children\n",
      "Node has multiple children. Testing replacement\n",
      "Trying optimal split\n",
      "[64.99999999999999, Node('/SepalLengthCm < 5.0', checked=False)]\n",
      "[63.49999999999999, Node('/SepalLengthCm < 5.3', checked=False)]\n",
      "[61.99999999999999, Node('/SepalLengthCm < 5.45', checked=False)]\n",
      "[55.99999999999999, Node('/SepalLengthCm < 5.55', checked=False)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-944997fc9d56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moptimalTree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0moptimalTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_local_optimum_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mprint_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimalTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#print(optimalTree)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-944997fc9d56>\u001b[0m in \u001b[0;36mbest_local_optimum_tree\u001b[1;34m(dataFrame, n, n_min, D_max, alpha)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Starting loop \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\": \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mstartingTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremainingLength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_min\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mlocalOptimalTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_node_modification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstartingTree\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mlocalLoss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocalOptimalTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseLineError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocalLoss\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbestLoss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-021a2562e9cf>\u001b[0m in \u001b[0;36mrandom_node_modification\u001b[1;34m(tree, dataFrame, n_min, D_max, alpha)\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trying optimal split\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mtestNode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m             \u001b[0mnewNode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataFrameNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseLineError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m             \u001b[0mnewLoss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewNode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseLineError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewLoss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-021a2562e9cf>\u001b[0m in \u001b[0;36mupdate_split\u001b[1;34m(node, dataFrame, n_min, alpha, baseLineError)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;31m# find optimal split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[1;31m# replace previous split with new optimal split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0moptimal_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseLineError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseLineError\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-021a2562e9cf>\u001b[0m in \u001b[0;36moptimal_split\u001b[1;34m(node, dataFrame, n_min, alpha, baseLineError)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;31m# create split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimal_node_data_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseLineError\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbaseLineError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[0mparent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-021a2562e9cf>\u001b[0m in \u001b[0;36moptimal_node_data_split\u001b[1;34m(node, dataFrame, operators, n_min, alpha, baseLineError)\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[0mnewNode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{feature} {operator} {value}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moperator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchildren\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchildNodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchecked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchildNodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                     \u001b[0mupdate_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewNode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                     \u001b[0mleftDataFrame\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrightDataFrame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moperator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-021a2562e9cf>\u001b[0m in \u001b[0;36mupdate_tree\u001b[1;34m(tree, dataFrame, n_min)\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;31m# split data by decision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mleftData\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrightData\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;31m# check if node is on left\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-a40b082bfdd6>\u001b[0m in \u001b[0;36msplit_data\u001b[1;34m(feature, operator, value, dataFrame)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mleftDataFrame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{feature} {operator} {value}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mrightDataFrame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataFrame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mdataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleftDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mleftDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mleftDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrightDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36misin\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m   7272\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7273\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7274\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7275\u001b[0m                 raise ValueError(\"cannot compute isin with \"\n\u001b[0;32m   7276\u001b[0m                                  \"a duplicate axis.\")\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mis_unique\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mis_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1556\u001b[0m         \u001b[1;34m\"\"\" return if the index has unique values \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1557\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1559\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Finds best local optimum tree with given hyperparameters and tree count\n",
    "def best_local_optimum_tree(dataFrame, n = 1, n_min = 1, D_max = 5, alpha = 0.5):\n",
    "    \n",
    "    # Initialse baseline\n",
    "    baseLineError = calculate_baseline_error(dataFrame)\n",
    "    \n",
    "    # Intiliase error for baseline leaf\n",
    "    optimalTree = create_leaf(dataFrame)\n",
    "    bestLoss = loss_function(optimalTree, dataFrame, alpha, baseLineError)\n",
    "    \n",
    "    # Loop through number of trees\n",
    "    for i in range(0,n):\n",
    "        \n",
    "        # Create random tree\n",
    "        startingTree = create_tree(dataFrame, get_features(dataFrame), remainingLength = 2, n_min = n_min)\n",
    "        \n",
    "        # Run optimal tree function to find local optimum tree\n",
    "        localOptimalTree = random_node_modification(startingTree,test_data,alpha = 0.5, D_max = 4, n_min = 2)\n",
    "        \n",
    "        # Get loss of local optimum tree\n",
    "        localLoss = loss_function(localOptimalTree, dataFrame, alpha, baseLineError)\n",
    "        \n",
    "        # Replace best tree with new local optimum tree if better\n",
    "        if(localLoss < bestLoss):\n",
    "            \n",
    "            optimalTree = copy.deepcopy(localOptimalTree)\n",
    "            \n",
    "            # Update best loss\n",
    "            bestLoss = localLoss\n",
    "    \n",
    "    return optimalTree\n",
    "\n",
    "optimalTree = best_local_optimum_tree(test_data, 10, 1, 4, 0.5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
